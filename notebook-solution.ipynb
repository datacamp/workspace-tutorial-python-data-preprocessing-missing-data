{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0eb4f16-5a99-460d-a5ba-706b7ef0bbe7",
   "metadata": {
    "id": "bA5ajAmk7XH6"
   },
   "source": [
    "## When do I need to care about missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d457a-a5e8-4131-a810-25e2044c94cf",
   "metadata": {},
   "source": [
    "If you don't know some of the values in your dataset, then you can't\n",
    "\n",
    "- calculate summary statistics\n",
    "- run most machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac23ce5-cf9e-4d47-8b3d-6c74efe08619",
   "metadata": {},
   "source": [
    "## Why is data sometimes missing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06600d7a-31e2-4474-9e60-12efc05e35d3",
   "metadata": {},
   "source": [
    "There are many reasons!\n",
    "\n",
    "- For survey data, perhaps someone declined to answer a question.\n",
    "- For website data, perhaps some users installed privacy tools so you could not track their behavior.\n",
    "- For sensor data, perhaps a sensor was not working, or a signal was too small to detect.\n",
    "\n",
    "Understanding why data is missing is crucial to deciding how best to deal with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6837de-dd29-42f5-8fda-30e03099c075",
   "metadata": {},
   "source": [
    "## How can I handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d210729-8929-43ec-8514-3807217b198b",
   "metadata": {},
   "source": [
    "There are essentially two choices:\n",
    "\n",
    "- Delete the missing data (drop the rows from your dataset)\n",
    "- Make up reasonable values (imputation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ee9f9-b495-40f2-8059-cb13adcefb88",
   "metadata": {},
   "source": [
    "## What are the steps for handling missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6407097-9558-421e-aa2e-cc760ca373ee",
   "metadata": {},
   "source": [
    "1. Standardize how missing values are recorded\n",
    "2. Quantify how much missing data you have\n",
    "3. Either delete or impute the missing values\n",
    "4. Run your model (or do other analysis)\n",
    "5. Check the effect of missing values on your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bfc28e-8578-45bc-a7b3-9bb1985431f3",
   "metadata": {},
   "source": [
    "## What Python packages can I use for handling missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca8054-b68f-4685-8ab2-62a0771470c1",
   "metadata": {},
   "source": [
    "- **pandas** (used here)\n",
    "- **scikit-learn** (used here)\n",
    "- **PyCaret**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50009e94-5d15-44a5-9c0a-57105466d626",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6416cd72-2ff1-4daa-b2c2-2fc183552454",
   "metadata": {},
   "source": [
    "- **Time series aren't covered here**. In time series data, rows at nearby time points are related, so they have their own methods for dealing with missing data.\n",
    "- **Survival analysis isn't covered here**. If values are missing because they exceed a threshold, then you have a survival analysis problem, which requires different techniques.\n",
    "- **Multiple imputation isn't covered here**. The most sophisticated techniques for dealing with missing data involve multiple imputation, but that isn't well supported in scikit-learn.\n",
    "- **Imputation is not valid when missing values are \"missing not at random\"**. If there is a pattern to the missingness caused by variables that aren't in the dataset, then the techniques discussed here aren't valid. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e7c8af-bca3-4c7b-938d-6569941fc6ed",
   "metadata": {},
   "source": [
    "## Case study: Mammalian sleep durations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb669127-b53d-4887-b3a4-cd731637357f",
   "metadata": {},
   "source": [
    "Let's explore a popular dataset on mammalian sleep durations, `msleep`. The dataset was cribbed from a 2007 paper by V. M. Savage and G. B. West and Wikipedia, and was popularized by R's **ggplot2** package. It's available in Python via the **plotnine** package.\n",
    "\n",
    "Since the dataset is a dataframe, we'll import **pandas** too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08cffff-c1cc-4237-b5ba-d005b1495ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotnine.data import msleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8c5330-1526-4038-b417-1ec3a7f39d17",
   "metadata": {},
   "source": [
    "Some extra code has been added to demonstrate issues with dirty data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91c0b0-8300-46f2-94a7-2eea3e7b1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "msleep_dirty = msleep.copy()\n",
    "msleep_dirty[\"conservation\"] = msleep_dirty[\"conservation\"].cat.set_categories([\"lc\", \"nt\", \"vu\", \"en\", \"cr\", \"ew\", \"ex\", \"unknown\"], ordered=True).fillna(value=\"unknown\")\n",
    "msleep_dirty[\"sleep_rem\"] = msleep_dirty[\"sleep_rem\"].fillna(value=-999)\n",
    "msleep_dirty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481a29ff-bd19-4f5f-91e9-08b02bb5501d",
   "metadata": {},
   "source": [
    "## Standardizing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc33774-ed0b-4f1f-82e1-3b71ff653ca2",
   "metadata": {},
   "source": [
    "Before we can deal with missing data, we must standardize the format of the missing values. That means\n",
    "\n",
    "- converting strings like `\"N/A\"` or `\"unknown\"` to true NAs.\n",
    "- converting code numbers like `-999` to true NAs.\n",
    "\n",
    "By a \"true NA\", I mean **NumPy**'s `nan` value. (**pandas** also has a special value for missing data, `NA`, but it isn't yet widely supported.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb3ac1-5e6c-4ced-b15f-c198dd740fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7309793a-2bec-4701-959a-1b94fbc188de",
   "metadata": {},
   "source": [
    "To standardize the missing values, we replace them using the [`.replace()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60592b7-7dd2-40f5-b66c-badf64afbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "msleep = msleep_dirty.replace(\n",
    "    {\"conservation\": \"unknown\", \"sleep_rem\": -999},\n",
    "    value=nan\n",
    ")\n",
    "msleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b455de7-1bf1-48d3-94d4-a5184b47bdca",
   "metadata": {},
   "source": [
    "Notice that the missing values in the `conservation` and `sleep_rem` columns now display as `NaN` or `null`, depending on your Jupyter notebook editor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ed0b42-b9f3-4f85-bf65-2db054131ba8",
   "metadata": {},
   "source": [
    "## Quantifying missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c8f664-42f8-40d8-a228-975775d97a9a",
   "metadata": {},
   "source": [
    "To decide on the best technique for handling missing data, we need to know how much there is. We can find the proportion of missing data in each column by combining the [`.isna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html) and [`.mean()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html) methods.\n",
    "\n",
    "A value of zero means no missing data, and a value of one means all values in the column are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f2834-1532-414a-8ecf-bc85aa7032c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "msleep.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e5d460-2d29-4377-b5bb-ca3840793f1d",
   "metadata": {},
   "source": [
    "`vore` has a small amount of missing data, with 8% missing. `sleep_cycle` has the most missing data, with 61% missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689aefcb-5a4c-4d04-a5da-2bb56e05625f",
   "metadata": {},
   "source": [
    "## Dropping rows with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685bb801-4b86-4031-b251-bc9254c1b62b",
   "metadata": {},
   "source": [
    "The simplest solution to handling missing data is to get rid of any rows where there is a missing value using the [.dropna()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f5ed2-f11e-44ba-b6bc-77551da54f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "msleep.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a31822c-88ad-4989-b66b-854b79003b3f",
   "metadata": {},
   "source": [
    "In this case, we've droppped most of the dataset, going from 83 rows to 12. This is far from ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709ea1a6-87df-4b26-9dd7-6f8ce815646d",
   "metadata": {},
   "source": [
    "Dropping data is only a suitable solution if there is only a very small amount of missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba1aa2-8f36-4fbb-b675-fbf06dad64bd",
   "metadata": {},
   "source": [
    "## Separating the dataset by column data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b1844-0048-4c5a-ab2d-133c243d167e",
   "metadata": {},
   "source": [
    "In **scikit-learn**, numeric data and unordered categorical data currently require different techniques for imputation. \n",
    "\n",
    "For ordered categorical data, you can either treat it in the same way as unordered categorical data, or transform in into integers with [`OrdinalEncoder()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html), and pretend that it is numeric. Here we'll take the former approach for simplicity.\n",
    "\n",
    "The next step is to split the dataset into two by column type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53615ce-0a36-4911-bfe9-0183a29f5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "msleep_num = msleep.select_dtypes(\"float\")\n",
    "msleep_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a826ab-f3cc-4e2a-95d2-3d67d3aa77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "msleep_cat = msleep.select_dtypes([\"object\", \"category\"])\n",
    "msleep_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbd4529-96fd-4d54-a815-c3c35ecef3fc",
   "metadata": {},
   "source": [
    "## Replacing with means or medians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79054536-0e24-4603-a2a4-d22655c22b1c",
   "metadata": {},
   "source": [
    "The simplest (and stupidest) imputation approach is to just to replace missing values with the mean or median of the column.\n",
    "\n",
    "We have two options: **scikit-learn**'s [`SimpleImputer()`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) and **pandas**'s [`.fillna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html).\n",
    "\n",
    "We'll focus on `SimpleImputer()` since it's easiest to transition to the more advanced imputers later, but check our working with `.fillna()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5cb59-6ebc-43fd-8123-2f8f2fb1cdfc",
   "metadata": {},
   "source": [
    "First we import the **impute** submodule of **scikit learn**, and create a `SimpleImputer()` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20356c28-6ec0-4eba-beaf-5cb32d48f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.impute as si\n",
    "simp = si.SimpleImputer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d9f3a9-9699-419a-ab1b-496384dfd90e",
   "metadata": {},
   "source": [
    "Now we call the [`.fit_transform()`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer.fit_transform) method. *Fitting* means calculating the mean of the columns, and *transforming* means replacing the missing values with those means.\n",
    "\n",
    "One annoyance is the **scikit-learn** only cares about **NumPy** arrays, so we have to manually convert it back to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb149e50-a27e-4894-829a-1cd6dfcee777",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(simp.fit_transform(msleep_num), columns=msleep_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a463f1e-4db2-4a30-b23a-ff7590dd1637",
   "metadata": {},
   "source": [
    "Before we get into the results, let's try this again with **pandas** to see how it works. We calculate the mean of each column (fit), and fill the missing values with those means (transform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aefb8c-7fa6-409f-86b6-9cbbf2464128",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = msleep_num.mean()\n",
    "msleep_num.fillna(column_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638bb04-a639-4297-9b66-bdcaffee5a2e",
   "metadata": {},
   "source": [
    "Notice that we have the same result in each case, so our code is correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f46781c-fba1-4954-bfb7-df9401dace34",
   "metadata": {},
   "source": [
    "Just like dropping data, imputing with the mean or median is only a suitable solution if\n",
    "\n",
    "1. There is only a very small amount of missing data, and\n",
    "2. anecdotally it performs better when you have lots of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca03f38-5b9e-422c-92e2-d95fabbbd675",
   "metadata": {},
   "source": [
    "## Replacing with the most frequent value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c2e83-7d4c-454d-92e2-22ee6282a4c3",
   "metadata": {},
   "source": [
    "For categorical columns, there is no mean, so an alternative is to use the mode. That is, the most frequent value in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00916560-7337-4f5a-9ee8-316562ef23af",
   "metadata": {},
   "outputs": [],
   "source": [
    "simp_mf = si.SimpleImputer(strategy=\"most_frequent\")\n",
    "pd.DataFrame(simp_mf.fit_transform(msleep_cat), columns=msleep_cat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dae8a89-3f83-4a8d-be34-6bbce7a3a2dc",
   "metadata": {},
   "source": [
    "Again, this isn't ideal, but there aren't really any good alternatives built-in to **scikit-learn**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdcdf51-b405-47dd-9ebd-4f6272caeb9e",
   "metadata": {},
   "source": [
    "## Using iterative methods to find the best replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f4806e-9d80-4dac-8e8e-147f41d85634",
   "metadata": {},
   "source": [
    "A more sophisticated option is to use [`IterativeImputer()`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html). This fits a predictive model (a Bayesian Ridge Regression) to each column, one at a time using the non missing values in the other columns. By repeating this process several times (iterating), more and more missing data gets filled in.\n",
    "\n",
    "As with replacing using the mean, this only works with numeric columns.\n",
    "\n",
    "`IterativeImputer()` should be your default starting point for most imputation. As of **scikit learn** `1.0.2`, it's considered  experimental, so you need to enable it before using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca283b-6bb5-4c95-834a-0b3c89725787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "iimp = si.IterativeImputer()\n",
    "pd.DataFrame(iimp.fit_transform(msleep_num), columns=msleep_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082f9d5-58ab-45f0-9cf3-16dad3c17393",
   "metadata": {},
   "source": [
    "Notice that this time, the first three mising values in `sleep_cycle` have been replaced with different values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747564ca-feb5-4cba-9fd6-0a52f21a305a",
   "metadata": {},
   "source": [
    "## Where can I learn more?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a730f2-ca49-440d-9f9f-3bfaf26ee736",
   "metadata": {},
   "source": [
    "- DataCamp's [Dealing with Missing Data in Python](https://app.datacamp.com/learn/courses/dealing-with-missing-data-in-python), [Cleaning Data in Python](https://app.datacamp.com/learn/courses/cleaning-data-in-python) and [Machine Learning with scikit-learn](https://app.datacamp.com/learn/courses/machine-learning-with-scikit-learn) courses.\n",
    "- pandas [Working with Missing Data](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html) tutorial.\n",
    "- scikit-learn [Imputation of missing values](https://scikit-learn.org/stable/modules/impute.html) tutorial."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataCamp Workspace",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
